# è®ºæ–‡è‡ªåŠ¨å½’æ¡£ç³»ç»Ÿ - å®ç°æ–¹æ¡ˆ

## 1. é¡¹ç›®æ¦‚è¿°

åŸºäº LangGraph æ„å»ºçš„åŠè‡ªåŠ¨è®ºæ–‡å½’æ¡£ç³»ç»Ÿï¼Œæ”¯æŒï¼š
- **é£ä¹¦æœºå™¨äººä½œä¸ºä¸»è¦å…¥å£** - å‘é€è®ºæ–‡é“¾æ¥å³å¯å¯åŠ¨å¤„ç†æµç¨‹
- è®ºæ–‡ URL â†’ LLM è‡ªåŠ¨ Triage â†’ äººå·¥å†³ç­–ï¼ˆé£ä¹¦å¡ç‰‡ï¼‰â†’ å½’æ¡£åˆ° Craft
- æ”¯æŒè‡ªå®šä¹‰ LLMï¼ˆå¯é…ç½® base_urlã€api_keyã€modelï¼‰

## 2. ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    subgraph Input
        A[arXiv URL] --> C[Paper Parser]
        B[PDF File] --> C
    end
    
    subgraph LangGraph Workflow
        C --> D[Ingest Node]
        D --> E[Extract Node]
        E --> F[Triage Node - LLM]
        F --> G[Upsert Base Archive]
        G --> H[INTERRUPT - äººå·¥å†³ç­–ç‚¹]
        H --> I[Apply Decision Node]
        I --> J{Decision?}
        J -->|Deep Read| K[Deep Read Node - LLM]
        K --> L[Create Reading Doc]
        L --> M[Update Archive]
        J -->|Skim/Drop| M
        M --> N[END]
    end
    
    subgraph External Services
        O[Craft API] <--> G
        O <--> L
        O <--> M
        P[é£ä¹¦æœºå™¨äºº] <--> H
        Q[LLM API] <--> F
        Q <--> K
    end
    
    subgraph Persistence
        R[SQLite Checkpointer]
        R <--> H
    end
```

## 3. å·¥ä½œæµçŠ¶æ€å›¾

```mermaid
stateDiagram-v2
    [*] --> Ingesting: æäº¤è®ºæ–‡URL/PDF
    Ingesting --> Extracting: å…ƒä¿¡æ¯æå–å®Œæˆ
    Extracting --> Triaging: æ–‡æœ¬æå–å®Œæˆ
    Triaging --> BaseArchived: Triageå®Œæˆå¹¶å½’æ¡£
    BaseArchived --> WaitingDecision: å‘é€é£ä¹¦å¡ç‰‡
    WaitingDecision --> ApplyingDecision: ç”¨æˆ·åšå‡ºå†³ç­–
    ApplyingDecision --> DeepReading: é€‰æ‹©ç²¾è¯»
    ApplyingDecision --> Completed: é€‰æ‹©é€Ÿè¯»/Drop
    DeepReading --> CreatingDoc: ç²¾è¯»ç¬”è®°ç”Ÿæˆå®Œæˆ
    CreatingDoc --> Completed: åˆ›å»ºCraftæ–‡æ¡£å¹¶æ›´æ–°å½’æ¡£
    Completed --> [*]
```

## 4. æ•°æ®ç»“æ„è®¾è®¡

### 4.1 Craft Collection Schemaï¼ˆè®ºæ–‡ç»Ÿè®¡ï¼‰

| å­—æ®µ Key | å­—æ®µå | ç±»å‹ | è¯´æ˜ |
|----------|--------|------|------|
| title | Title | string | è®ºæ–‡æ ‡é¢˜ |
| `` | æ–‡ç« æ–¹å‘ | multi-select | AI Infra, MultiMode, Agent, Context Engineering, Memory, Agentåä½œ, Coding, Reasoning, Bench, Pre-Training, LLM, Post-Training, RAG |
| _2 | é“¾æ¥ | URL | è®ºæ–‡åŸå§‹é“¾æ¥ |
| _3 | æ¦‚è¦ | text | LLM ç”Ÿæˆçš„æ¦‚è¦ |
| _4 | åŸæ–‡é˜…è¯» | block link | é“¾æ¥åˆ°ç²¾è¯»æ–‡æ¡£ |
| _5 | æ˜¯å¦ç²¾è¯» | single-select | Yes / No |
| _6 | é€Ÿè¯»é“¾æ¥ | URL | é€Ÿè¯»ç¬”è®°é“¾æ¥ï¼ˆå¯é€‰ï¼‰ |
| _7 | è¯„è®º | text | ä¸ªäººè¯„è®º |

### 4.2 ç²¾è¯»æ¨¡æ¿ç»“æ„

```markdown
# è®ºæ–‡ç²¾è¯»æ¨¡ç‰ˆ

## ğŸ“œ æ–‡ç« æ¦‚è¿°
[LLM ç”Ÿæˆçš„è¯¦ç»†æ¦‚è¿°]

## ğŸ’¡åˆ›æ–°ç‚¹
[LLM åˆ†æçš„åˆ›æ–°ç‚¹]

## ğŸŒŒå¯èƒ½ç»“åˆçš„æ–¹å‘
[LLM å»ºè®®çš„ç ”ç©¶æ–¹å‘]

## ğŸ¤”æ€è€ƒå’Œæ„Ÿæƒ³
[ç”¨æˆ·åç»­å¡«å†™]
```

### 4.3 LangGraph State Schema

```python
from typing import TypedDict, Optional, List, Literal
from enum import Enum

class DecisionType(str, Enum):
    DEEP_READ = "deep_read"
    SKIM = "skim"
    DROP = "drop"

class PaperState(TypedDict):
    # è¾“å…¥
    paper_id: str  # ç”± URL/DOI hash ç”Ÿæˆ
    source_url: str
    source_type: Literal["arxiv", "pdf", "url"]
    
    # å…ƒä¿¡æ¯
    title: Optional[str]
    authors: Optional[List[str]]
    year: Optional[int]
    abstract: Optional[str]
    
    # æå–çš„å†…å®¹
    full_text: Optional[str]
    
    # Triage ç»“æœ
    triage_summary: Optional[str]  # æ¦‚è¦
    triage_contributions: Optional[str]  # è´¡çŒ®ç‚¹
    triage_limitations: Optional[str]  # å±€é™æ€§
    triage_relevance: Optional[int]  # ç›¸å…³æ€§è¯„åˆ† 1-5
    triage_suggested_action: Optional[DecisionType]  # LLM å»ºè®®
    triage_suggested_tags: Optional[List[str]]  # å»ºè®®çš„æ–‡ç« æ–¹å‘
    
    # Craft å½’æ¡£
    craft_collection_item_id: Optional[str]
    craft_reading_doc_id: Optional[str]
    
    # äººå·¥å†³ç­–
    human_decision: Optional[DecisionType]
    human_tags: Optional[List[str]]
    human_comment: Optional[str]
    
    # Deep Read ç»“æœ
    deep_read_overview: Optional[str]  # ğŸ“œ æ–‡ç« æ¦‚è¿°
    deep_read_innovations: Optional[str]  # ğŸ’¡åˆ›æ–°ç‚¹
    deep_read_directions: Optional[str]  # ğŸŒŒå¯èƒ½ç»“åˆçš„æ–¹å‘
    
    # çŠ¶æ€
    status: Literal["ingesting", "extracting", "triaging", "waiting_decision", "deep_reading", "completed", "failed"]
    error_message: Optional[str]
```

### 4.4 é£ä¹¦å¡ç‰‡ Payload

```json
{
  "paper_id": "abc123",
  "title": "è®ºæ–‡æ ‡é¢˜",
  "source_url": "https://arxiv.org/abs/...",
  "triage_summary": "è¿™ç¯‡è®ºæ–‡æå‡ºäº†...",
  "triage_contributions": "1. xxx\n2. xxx",
  "triage_relevance": 4,
  "triage_suggested_action": "deep_read",
  "triage_suggested_tags": ["Agent", "Reasoning"],
  "actions": [
    {"label": "ğŸ“– ç²¾è¯»", "value": "deep_read"},
    {"label": "ğŸ‘€ é€Ÿè¯»", "value": "skim"},
    {"label": "ğŸ—‘ï¸ Drop", "value": "drop"}
  ]
}
```

## 5. é¡¹ç›®ç›®å½•ç»“æ„

```
read_paper_auto/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI å…¥å£
â”‚   â”œâ”€â”€ config.py               # é…ç½®ç®¡ç†
â”‚   â”‚
â”‚   â”œâ”€â”€ workflow/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ graph.py            # LangGraph å·¥ä½œæµå®šä¹‰
â”‚   â”‚   â”œâ”€â”€ state.py            # State Schema
â”‚   â”‚   â””â”€â”€ nodes/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ ingest.py       # è®ºæ–‡è¾“å…¥è§£æ
â”‚   â”‚       â”œâ”€â”€ extract.py      # æ–‡æœ¬æå–
â”‚   â”‚       â”œâ”€â”€ triage.py       # LLM Triage
â”‚   â”‚       â”œâ”€â”€ archive.py      # Craft å½’æ¡£æ“ä½œ
â”‚   â”‚       â”œâ”€â”€ decision.py     # äººå·¥å†³ç­–å¤„ç†
â”‚   â”‚       â””â”€â”€ deep_read.py    # ç²¾è¯»ç¬”è®°ç”Ÿæˆ
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ craft_client.py     # Craft API å®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ llm_client.py       # LLM API å®¢æˆ·ç«¯ï¼ˆå¯é…ç½®ï¼‰
â”‚   â”‚   â”œâ”€â”€ feishu_bot.py       # é£ä¹¦æœºå™¨äºº
â”‚   â”‚   â””â”€â”€ paper_parser.py     # è®ºæ–‡è§£æï¼ˆarXiv/PDFï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py           # API è·¯ç”±
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic æ¨¡å‹
â”‚   â”‚
â”‚   â””â”€â”€ persistence/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ checkpointer.py     # SQLite Checkpointer
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ .env.example                # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## 6. ç¯å¢ƒé…ç½®

### .env.example

```bash
# LLM é…ç½®ï¼ˆæ”¯æŒè‡ªå®šä¹‰ï¼‰
LLM_BASE_URL=https://api.openai.com/v1
LLM_API_KEY=your-api-key
LLM_MODEL_NAME=gpt-4

# Craft API
CRAFT_API_BASE_URL=https://connect.craft.do/links/<YOUR_CRAFT_LINK_ID>/api/v1
CRAFT_COLLECTION_ID=your-collection-id
CRAFT_READING_TEMPLATE_ID=your-template-block-id

# é£ä¹¦æœºå™¨äºº
FEISHU_APP_ID=your-app-id
FEISHU_APP_SECRET=your-app-secret
FEISHU_BOT_WEBHOOK=https://open.feishu.cn/open-apis/bot/v2/hook/xxx

# æœåŠ¡é…ç½®
SERVER_HOST=0.0.0.0
SERVER_PORT=9999

# æŒä¹…åŒ–
SQLITE_DB_PATH=./data/workflow.db
```

## 7. API æ¥å£è®¾è®¡

### 7.1 POST /triage

æäº¤è®ºæ–‡è¿›è¡Œ Triage å¤„ç†ã€‚

**Request:**
```json
{
  "source_url": "https://arxiv.org/abs/2401.xxxxx",
  "source_type": "arxiv"
}
```

**Response:**
```json
{
  "paper_id": "abc123",
  "status": "waiting_decision",
  "triage_result": {
    "title": "è®ºæ–‡æ ‡é¢˜",
    "summary": "æ¦‚è¦...",
    "suggested_action": "deep_read",
    "suggested_tags": ["Agent", "Reasoning"]
  }
}
```

### 7.2 POST /resume

æäº¤äººå·¥å†³ç­–ï¼Œç»§ç»­å·¥ä½œæµã€‚

**Request:**
```json
{
  "paper_id": "abc123",
  "decision": "deep_read",
  "tags": ["Agent", "Reasoning"],
  "comment": "è¿™ç¯‡è®ºæ–‡å¾ˆæœ‰ä»·å€¼"
}
```

**Response:**
```json
{
  "paper_id": "abc123",
  "status": "completed",
  "craft_item_id": "xxx",
  "craft_reading_doc_id": "yyy"
}
```

### 7.3 GET /paper/{paper_id}

æŸ¥è¯¢è®ºæ–‡å¤„ç†çŠ¶æ€ã€‚

**Response:**
```json
{
  "paper_id": "abc123",
  "status": "waiting_decision",
  "title": "è®ºæ–‡æ ‡é¢˜",
  "source_url": "https://...",
  "triage_result": {...},
  "decision": null,
  "craft_item_id": "xxx"
}
```

### 7.4 POST /feishu/callback

é£ä¹¦æœºå™¨äººå›è°ƒæ¥å£ã€‚

## 8. é£ä¹¦æœºå™¨äººäº¤äº’æµç¨‹ï¼ˆä¸»å…¥å£ï¼‰

**æ ¸å¿ƒäº¤äº’æ–¹å¼ï¼šç”¨æˆ·åœ¨é£ä¹¦å‘é€è®ºæ–‡é“¾æ¥ â†’ æœºå™¨äººè‡ªåŠ¨å¤„ç† â†’ è¿”å›å†³ç­–å¡ç‰‡ â†’ ç”¨æˆ·ç‚¹å‡»å†³ç­– â†’ å®Œæˆå½’æ¡£**

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as é£ä¹¦æœºå™¨äºº
    participant S as åç«¯æœåŠ¡
    participant W as LangGraph Workflow
    participant C as Craft API

    U->>F: å‘é€è®ºæ–‡é“¾æ¥
    F->>S: POST /feishu/message æ¥æ”¶æ¶ˆæ¯
    S->>S: è§£æé“¾æ¥æå–URL
    S->>W: å¯åŠ¨å·¥ä½œæµ
    F->>U: å›å¤ï¼šæ­£åœ¨å¤„ç†...
    W->>W: Ingest â†’ Extract â†’ Triage
    W->>C: åˆ›å»ºåŸºç¡€å½’æ¡£æ¡ç›®
    W->>W: INTERRUPT ç­‰å¾…å†³ç­–
    W->>F: å‘é€å†³ç­–å¡ç‰‡
    F->>U: å±•ç¤ºå†³ç­–å¡ç‰‡
    U->>F: ç‚¹å‡»æŒ‰é’®åšå‡ºå†³ç­–
    F->>S: POST /feishu/action å¡ç‰‡å›è°ƒ
    S->>W: Resume å·¥ä½œæµ
    alt Deep Read
        W->>W: ç”Ÿæˆç²¾è¯»ç¬”è®°
        W->>C: åˆ›å»ºç²¾è¯»æ–‡æ¡£
        W->>C: æ›´æ–°å½’æ¡£æ¡ç›®
    else Skim/Drop
        W->>C: æ›´æ–°å½’æ¡£æ¡ç›®çŠ¶æ€
    end
    W->>F: å‘é€å®Œæˆé€šçŸ¥
    F->>U: å±•ç¤ºç»“æœå’ŒCrafté“¾æ¥
```

### 8.1 é£ä¹¦æœºå™¨äººæ¶ˆæ¯å¤„ç†

ç”¨æˆ·å‘é€çš„æ¶ˆæ¯æ ¼å¼ï¼š
- ç›´æ¥å‘é€ arXiv é“¾æ¥ï¼š`https://arxiv.org/abs/2401.xxxxx`
- å‘é€å¸¦è¯´æ˜çš„é“¾æ¥ï¼š`çœ‹çœ‹è¿™ç¯‡ https://arxiv.org/abs/2401.xxxxx`

æœºå™¨äººè‡ªåŠ¨è¯†åˆ«é“¾æ¥å¹¶å¯åŠ¨å¤„ç†æµç¨‹ã€‚

### 8.2 é£ä¹¦ API æ¥å£

| æ¥å£ | è¯´æ˜ |
|------|------|
| POST /feishu/message | æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯ï¼Œè§£æé“¾æ¥å¹¶å¯åŠ¨å·¥ä½œæµ |
| POST /feishu/action | æ¥æ”¶å¡ç‰‡æŒ‰é’®ç‚¹å‡»å›è°ƒï¼Œç»§ç»­å·¥ä½œæµ |

## 9. å®ç°æ­¥éª¤

### Phase 1: åŸºç¡€æ¡†æ¶
1. åˆ›å»ºé¡¹ç›®ç»“æ„å’Œé…ç½®æ–‡ä»¶
2. å®ç° Craft API å®¢æˆ·ç«¯
3. å®ç°å¯é…ç½®çš„ LLM å®¢æˆ·ç«¯

### Phase 2: æ ¸å¿ƒå·¥ä½œæµ
4. å®ç°è®ºæ–‡è§£ææ¨¡å—ï¼ˆarXiv/PDFï¼‰
5. å®ç° LLM Triage èŠ‚ç‚¹
6. å®ç° LangGraph å·¥ä½œæµï¼ˆå« interruptï¼‰
7. å®ç° SQLite Checkpointer

### Phase 3: é›†æˆä¸æ¥å£
8. å®ç° FastAPI åç«¯æœåŠ¡
9. å®ç°é£ä¹¦æœºå™¨äººé›†æˆ
10. å®ç° Deep Read ç²¾è¯»æ¨¡å—

### Phase 4: éƒ¨ç½²ä¸æ–‡æ¡£
11. ç¼–å†™ Dockerfile å’Œ docker-compose
12. ç¼–å†™ä½¿ç”¨æ–‡æ¡£

## 10. å…³é”®æŠ€æœ¯ç‚¹

### 10.1 LangGraph Interrupt æœºåˆ¶

```python
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.graph import StateGraph
from langgraph.types import interrupt

def human_decision_node(state: PaperState) -> PaperState:
    # å‘é€é£ä¹¦å¡ç‰‡
    send_feishu_card(state)
    
    # ä¸­æ–­ç­‰å¾…äººå·¥å†³ç­–
    decision = interrupt({
        "paper_id": state["paper_id"],
        "title": state["title"],
        "triage_summary": state["triage_summary"],
        "suggested_action": state["triage
